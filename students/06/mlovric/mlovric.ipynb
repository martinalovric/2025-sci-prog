{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"19pBjELzKy1GGPdZClqHiWdD8IoGsJemR","timestamp":1764855411928}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# install and import libraries\n","import google.generativeai as genai\n","import json\n","import time\n","import random\n","import re\n","\n","from google.api_core.exceptions import TooManyRequests\n","from google.colab import userdata\n","\n","GOOGLE_API_KEY = userdata.get('api_new')\n","\n","# configure Gemini\n","genai.configure(api_key=GOOGLE_API_KEY)\n","\n","# define models:\n","# - thinking_model: bigger model for feedback / optimization\n","# - lite_model: smaller model we want to improve\n","thinking_model = genai.GenerativeModel('gemini-2.5-pro')\n","lite_model = genai.GenerativeModel('gemini-2.0-flash-lite')"],"metadata":{"id":"5yZ6tUnZl5vT","executionInfo":{"status":"ok","timestamp":1764857336991,"user_tz":-60,"elapsed":6880,"user":{"displayName":"Martina Lovrić","userId":"03421384235659318155"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# simple retry helper for handling 429 (TooManyRequests) errors\n","def call_with_retry(func, max_retries=5):\n","    for attempt in range(max_retries):\n","        try:\n","            return func()\n","        except TooManyRequests as e:\n","            # if API suggests retry_after, use it; otherwise exponential backoff\n","            retry_after = getattr(e, \"retry_after\", None)\n","            if retry_after is None:\n","                retry_after = 2 ** attempt + random.random()\n","            print(f\"Quota hit, retrying in {retry_after:.2f} seconds...\")\n","            time.sleep(retry_after)\n","    raise Exception(\"Max retries exceeded\")\n","\n","\n","# call lite model (small model) and get text output\n","def generate_with_lite(prompt: str) -> str:\n","    def _call():\n","        response = lite_model.generate_content(prompt)\n","        return getattr(response, \"text\", str(response))\n","    return call_with_retry(_call)\n","\n","\n","# use thinking model to give feedback and a better prompt\n","def get_feedback_and_optimized_prompt(lite_model_prompt: str,\n","                                      lite_model_output: str) -> dict:\n","    \"\"\"\n","    Use the thinking_model to:\n","    - Evaluate the lite model's output\n","    - Suggest a better prompt\n","    - Explain the feedback and reasoning\n","\n","    Returns a dict with:\n","      - optimized_prompt\n","      - feedback_text\n","      - rationale\n","    \"\"\"\n","\n","    optimization_prompt = f\"\"\"\n","You are a prompt optimizer for a small text-generation model (\"lite model\").\n","\n","Your job:\n","- Look at the original prompt and the lite model's output.\n","- Improve the prompt so the lite model can give a better answer next time.\n","- Explain what was weak about the answer and why the new prompt should help.\n","\n","Rules:\n","- Keep the same basic goal as the original prompt.\n","- Focus on: clarity, style instructions, format, constraints, etc.\n","- Be practical and concise.\n","\n","Return ONLY valid JSON with exactly these keys:\n","{{\n","  \"optimized_prompt\": \"...\",\n","  \"feedback_text\": \"...\",\n","  \"rationale\": \"...\"\n","}}\n","\n","Do NOT include anything before or after the JSON.\n","\n","ORIGINAL_PROMPT:\n","{lite_model_prompt}\n","\n","LITE_MODEL_OUTPUT:\n","{lite_model_output}\n","\"\"\"\n","\n","    def _call():\n","        response = thinking_model.generate_content(optimization_prompt)\n","        return getattr(response, \"text\", str(response))\n","\n","    raw_text = call_with_retry(_call).strip()\n","\n","    # try to extract JSON from ```json ... ``` block if it exists\n","    match = re.search(r\"```json\\s*([\\s\\S]*?)\\s*```\", raw_text)\n","    if match:\n","        json_str = match.group(1).strip()\n","    else:\n","        json_str = raw_text\n","\n","    try:\n","        data = json.loads(json_str)\n","    except json.JSONDecodeError:\n","        # if parsing fails, keep the original prompt\n","        print(\"Could not parse JSON from thinking model response.\")\n","        print(\"Raw thinking model response:\\n\", raw_text)\n","        return {\n","            \"optimized_prompt\": lite_model_prompt,\n","            \"feedback_text\": (\n","                \"Could not parse JSON from thinking model. \"\n","                \"Keeping the original prompt.\"\n","            ),\n","            \"rationale\": (\n","                \"JSON parsing failed, so the prompt was not changed in this iteration.\"\n","            ),\n","        }\n","\n","    return {\n","        \"optimized_prompt\": data.get(\"optimized_prompt\", lite_model_prompt),\n","        \"feedback_text\": data.get(\"feedback_text\", \"\"),\n","        \"rationale\": data.get(\"rationale\", \"\"),\n","    }\n"],"metadata":{"id":"VNxBtpKXmnQI","executionInfo":{"status":"ok","timestamp":1764857337009,"user_tz":-60,"elapsed":23,"user":{"displayName":"Martina Lovrić","userId":"03421384235659318155"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def run_optimization_loop(initial_prompt: str, num_turns: int = 5):\n","    \"\"\"\n","    Optimization loop:\n","\n","    For each turn:\n","      1. Send current prompt to lite model.\n","      2. Get lite model output.\n","      3. Ask thinking model to:\n","         - give feedback,\n","         - explain reasoning,\n","         - propose a better prompt.\n","      4. Use the improved prompt in the next turn.\n","    \"\"\"\n","    current_prompt = initial_prompt\n","\n","    print(\"=== START PROMPT OPTIMIZATION (healthy recipes) ===\\n\")\n","\n","    for turn in range(1, num_turns + 1):\n","        print(f\"\\n--- TURN {turn} ---\")\n","\n","        # show current prompt\n","        print(\"\\nCurrent prompt for lite model:\")\n","        print(\"----------------------------------------\")\n","        print(current_prompt)\n","        print(\"----------------------------------------\")\n","\n","        # get lite model output\n","        print(\"\\n[1] Calling lite_model...\")\n","        lite_output = generate_with_lite(current_prompt)\n","        print(\"Lite model output:\")\n","        print(\"----------------------------------------\")\n","        print(lite_output)\n","        print(\"----------------------------------------\")\n","\n","        # get feedback + optimized prompt from thinking model\n","        print(\"\\n[2] Getting feedback and optimized prompt from thinking_model...\")\n","        feedback = get_feedback_and_optimized_prompt(current_prompt, lite_output)\n","\n","        print(\"\\nFeedback:\")\n","        print(\"----------------------------------------\")\n","        print(feedback[\"feedback_text\"])\n","        print(\"----------------------------------------\")\n","\n","        print(\"\\nRationale:\")\n","        print(\"----------------------------------------\")\n","        print(feedback[\"rationale\"])\n","        print(\"----------------------------------------\")\n","\n","        print(\"\\nNew optimized prompt for next turn:\")\n","        print(\"----------------------------------------\")\n","        print(feedback[\"optimized_prompt\"])\n","        print(\"----------------------------------------\")\n","\n","        # update prompt\n","        current_prompt = feedback[\"optimized_prompt\"]\n","\n","    print(\"\\n=== END OF OPTIMIZATION ===\")\n","    print(\"\\nFinal optimized prompt:\")\n","    print(\"----------------------------------------\")\n","    print(current_prompt)\n","    print(\"----------------------------------------\")\n","\n","# prompt\n","initial_prompt = \"Suggest a healthy dinner recipe that is high in protein.\"\n","\n","# number of optimization cycles\n","num_iterations = 5\n","\n","# run\n","run_optimization_loop(initial_prompt, num_iterations)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DGeYG8P3mqtv","executionInfo":{"status":"error","timestamp":1764857345569,"user_tz":-60,"elapsed":8557,"user":{"displayName":"Martina Lovrić","userId":"03421384235659318155"}},"outputId":"2fecb57a-4330-48bc-aa0e-a3bb72b9f19c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["=== START PROMPT OPTIMIZATION (healthy recipes) ===\n","\n","\n","--- TURN 1 ---\n","\n","Current prompt for lite model:\n","----------------------------------------\n","Suggest a healthy dinner recipe that is high in protein.\n","----------------------------------------\n","\n","[1] Calling lite_model...\n","Lite model output:\n","----------------------------------------\n","## Grilled Salmon with Quinoa & Roasted Asparagus\n","\n","This recipe is packed with protein from the salmon and quinoa, and also provides healthy fats, fiber, and vitamins from the vegetables.\n","\n","**Yields:** 2 servings\n","**Prep time:** 15 minutes\n","**Cook time:** 20 minutes\n","\n","**Ingredients:**\n","\n","*   **For the Salmon:**\n","    *   2 salmon fillets (4-6 oz each), skin on or off, your preference\n","    *   1 tbsp olive oil\n","    *   1 tbsp lemon juice\n","    *   1 clove garlic, minced\n","    *   Salt and black pepper to taste\n","    *   Optional: Fresh dill or parsley for garnish\n","*   **For the Quinoa:**\n","    *   1 cup quinoa, rinsed\n","    *   2 cups water or vegetable broth\n","    *   Salt to taste\n","*   **For the Roasted Asparagus:**\n","    *   1 bunch asparagus, trimmed\n","    *   1 tbsp olive oil\n","    *   Salt and black pepper to taste\n","    *   Optional: Garlic powder, red pepper flakes\n","\n","**Instructions:**\n","\n","**1. Prepare the Quinoa:**\n","\n","*   In a medium saucepan, combine the rinsed quinoa, water or vegetable broth, and a pinch of salt.\n","*   Bring to a boil over medium-high heat, then reduce heat to low, cover, and simmer for 15 minutes, or until all the liquid is absorbed and the quinoa is fluffy.\n","*   Fluff with a fork and set aside.\n","\n","**2. Prepare the Asparagus:**\n","\n","*   Preheat oven to 400°F (200°C).\n","*   Place the trimmed asparagus on a baking sheet.\n","*   Drizzle with olive oil, salt, pepper (and any other optional spices). Toss to coat.\n","*   Roast for 10-15 minutes, or until the asparagus is tender-crisp.\n","\n","**3. Prepare the Salmon:**\n","\n","*   In a small bowl, whisk together the olive oil, lemon juice, minced garlic, salt, and pepper.\n","*   Place the salmon fillets on a plate or in a shallow dish.\n","*   Brush the salmon with the lemon-garlic mixture.\n","*   **Grilling Option:** Preheat your grill to medium-high heat. Place the salmon skin-side down (if using skin-on fillets) on the grill. Cook for 4-6 minutes per side, or until the salmon is cooked through and flakes easily with a fork.\n","*   **Pan-Seared Option:** Heat a skillet over medium-high heat. Add a bit of oil to the pan. Place the salmon, skin-side down (if using skin-on fillets) in the skillet and cook for 4-6 minutes, or until the skin is crispy and golden brown. Flip and cook for another 2-4 minutes, or until the salmon is cooked through and flakes easily.\n","\n","**4. Assemble and Serve:**\n","\n","*   Divide the cooked quinoa between two plates.\n","*   Top with the roasted asparagus.\n","*   Place a salmon fillet on each plate.\n","*   Garnish with fresh dill or parsley, if desired.\n","\n","**Nutritional Information (per serving, approximate):**\n","\n","*   Calories: 500-600\n","*   Protein: 40-50g\n","*   Fat: 25-35g (mostly healthy fats from salmon and olive oil)\n","*   Carbohydrates: 30-40g\n","*   Fiber: 5-8g\n","\n","**Tips & Variations:**\n","\n","*   **Spice it up:** Add a pinch of red pepper flakes to the asparagus or the salmon marinade.\n","*   **Change the veggies:**  Use broccoli, Brussels sprouts, bell peppers, or any other vegetables you enjoy roasting.\n","*   **Add flavor to the quinoa:** Cook the quinoa in vegetable broth for extra flavor.  Add a squeeze of lime juice and some chopped cilantro after cooking.\n","*   **Marinade the salmon longer:**  Marinate the salmon in the lemon-garlic mixture for up to 30 minutes for a more intense flavor.\n","*   **Add healthy fats:** Drizzle with a balsamic glaze for extra flavor and healthy fats.  Add a few avocado slices to your plate.\n","\n","Enjoy your delicious and healthy high-protein dinner!\n","\n","----------------------------------------\n","\n","[2] Getting feedback and optimized prompt from thinking_model...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 229.53ms\n"]},{"output_type":"error","ename":"BadRequest","evalue":"400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: API key expired. Please renew the API key.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1443647129.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mrun_optimization_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-1443647129.py\u001b[0m in \u001b[0;36mrun_optimization_loop\u001b[0;34m(initial_prompt, num_turns)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# get feedback + optimized prompt from thinking model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[2] Getting feedback and optimized prompt from thinking_model...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfeedback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feedback_and_optimized_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlite_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFeedback:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-680995380.py\u001b[0m in \u001b[0;36mget_feedback_and_optimized_prompt\u001b[0;34m(lite_model_prompt, lite_model_output)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# try to extract JSON from ```json ... ``` block if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-680995380.py\u001b[0m in \u001b[0;36mcall_with_retry\u001b[0;34m(func, max_retries)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattempt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTooManyRequests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# if API suggests retry_after, use it; otherwise exponential backoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-680995380.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthinking_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimization_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mBadRequest\u001b[0m: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: API key expired. Please renew the API key."]}]}]}