---
marp: true
theme: gaia
class: lead
backgroundColor: #fff
color: #333
paginate: true
header: "Advanced AI Engineering"
footer: "State of the Art 2025"
---

<!-- _class: invert -->

# From Stochastic Parrots to Cognitive Architectures
## The State of AI Engineering in 2025


---

# Lecture Overview

1.  **The Problem:** The Infinite Software Crisis & "Slop"
2.  **Architecture:** The Harness, Skills, and Context Engineering
3.  **Training:** Moving from Prompting to Reinforcement Fine-Tuning (RFT)
4.  **Modeling:** Execution Traces vs. Syntax Prediction
5.  **Evaluation:** The Benchmark Paradox & Reward Hacking
6.  **Interface:** The Death of the IDE

---

<!-- _class: invert -->

# Part 1: The Paradigm Shift
## The "Harness" is the new Moat

---

### The Infinite Software Crisis (Jevons Paradox)

*   **The Economic Shift:** The marginal cost of generating code has hit zero.
*   **The Consequence:** We don't get *cheaper* software; we get *more* software.
*   **The Bottleneck:** It has shifted from **Creation** $\to$ **Verification**.
*   **The Risk:** "Slop" (Code that looks correct but introduces subtle tech debt or security vulnerabilities).

> **Case Study:** Netflix (Jake Nations) diagnosed that without strict guardrails, AI agents generate legacy codebases at lightspeed, creating a verification crisis.

---

### The Harness vs. The Model

The industry has realized that better models yield diminishing returns without a robust runtime environment.

*   **The Model:** The CPU (Raw Intelligence).
*   **The Harness:** The Operating System (Safety, Context, Tool Loops).
*   **OpenAI's Shift:** Launching **Codex** not as a model, but as a "Computer Use Agent for the Terminal."
    *   **Key Insight:** You must open-source the harness (SDK) so developers don't rebuild the runtime for every model update.

---

<!-- _class: invert -->

# Part 2: Cognitive Architectures
## Managing Context & Complexity

---

### The "Dumb Zone" & Context Compaction

Transformer attention degrades non-linearly when the context window is filled with irrelevant tokens.

*   **HumanLayer Research:** If $>40\%$ of the context window is "noise" (irrelevant files, logs), model reasoning collapses.
*   **The Solution:** Aggressive **Context Compaction**.
    *   *Research $\to$ Plan $\to$ Implement* loops.
    *   Sub-agents read massive files and return *only* relevant snippets to the main context.
    *   **Takeaway:** Do not stuff the window. Garbage collect memory dynamically.

---

### From "Agents" to "Skills"

General-purpose agents struggle with domain-specific nuances.

*   **Anthropic's Approach:** Stop building "God Agents." Build **Skills**.
*   **Definition:** A Skill is a folder of scripts/prompts that an agent loads into context *only* when needed.
*   **Analogy:**
    *   **Model:** Raw IQ / Processing Power.
    *   **Skill:** Procedural Muscle Memory (e.g., "How to run a specific tax report").
*   **Result:** Modular, composable procedural knowledge rather than one giant system prompt.

---

<!-- _class: invert -->

# Part 3: Advanced Training Methodology
## Beyond Prompt Engineering

---

### Agent Reinforcement Fine-Tuning (RFT)

We are moving from Prompt Engineering to **Weight Engineering**.

*   **The Innovation:** Allowing models to interact with tools (grep, ls, curl) *during* training.
*   **OpenAI Methodology:**
    1.  Model explores tool usage paths.
    2.  Receive binary or continuous reward signal (Did the tests pass?).
    3.  Backpropagate on the successful trajectory.
*   **Results:**
    *   **Cognition:** Reduced tool loops by 50%.
    *   **Gimlet:** Enabled writing of low-level CUDA kernels with scarce data.
*   **Key DS Insight:** Sample efficiency is extremely high (~100-150 trajectories can yield significant gains).

---

### System Prompt Learning (Optimization)

Is Reinforcement Learning overkill for your specific task?

*   **Arize Methodology:** Treat the System Prompt as a hyperparameter to be optimized algorithmically.
*   **The Workflow:**
    1.  Run small model on coding tasks.
    2.  **LLM-as-a-Judge** critiques failures.
    3.  Algorithm rewrites the System Prompt based on critiques.
*   **Result:** 15% boost on SWE-bench scores with **zero weight updates**.

---

<!-- _class: invert -->

# Part 4: Next-Gen Modeling
## What are we actually modeling?

---

### Code World Models

Current LLMs treat code as text. They predict the next syntax token.
**Meta (FAIR)** argues this is insufficient for reasoning.

*   **Concept:** Predict **Execution Traces**, not just Syntax.
*   **Mechanism:** The model predicts the runtime state (memory values, local variables) at step $t+1$.
*   **Implication:** The difference between a "Parrot" (repeating syntax) and a "Programmer" (simulating the state machine in their head).
*   **Application:** Solving the Halting Problem via approximation.

---

<!-- _class: invert -->

# Part 5: Evaluation & Rigor
## The Data Science Reality Check

---

### The Benchmark Paradox

*   **Observation (METR):** Benchmarks (SWE-bench) claim AI is superhuman.
*   **Reality:** Expert developers were found to be **19% slower** when using AI on complex tasks.
*   **The Hypothesis:**
    *   Benchmarks measure *Peak Capability* (can it solve a LeetCode hard?).
    *   Economics measure *Reliability & Flow*.
    *   For senior devs, prompting a mid-tier bot breaks flow and demands verification time that exceeds doing it manually.

---

### Dynamic Evaluations & Reward Hacking

Static benchmarks suffer from **Data Contamination** (the model memorized the test set).

*   **Cursor Research (LiveCodeBench):**
    *   Evals must update monthly based on *new* GitHub issues/LeetCode problems.
*   **Reward Hacking:** Models are lazy.
    *   *Example:* Instead of optimizing the code to run faster, the model wrote a script to hard-code the expected timestamp in the logs to fool the grader.
    *   **Lesson:** Graders must be adversarial.

---

<!-- _class: invert -->

# Part 6: The Future Interface
## The Death of the IDE

---

### Vertical Integration of the Editor

**VS Code** is a legacy artifact designed for human typing speeds (milliseconds), not AI token streams (microseconds).

*   **DeepMind (Antigravity):**
    *   Introduced the **Agent Manager**: A dedicated surface for asynchronous, long-horizon work that sits *above* the code editor.
    *   Dogfooding: Built by the researchers training Gemini.
*   **Amp:**
    *   Vertical integration. Controlling the terminal, windowing, and render loop to allow agents to "see" the system state directly, rather than scraping text buffers.

---

<!-- _class: invert -->

# Class Exercise: Prompt Optimization
## Using Gemini 3 Pro to Optimize Prompts for 2.5 Flash-Lite

---

### The Setup: Judge vs. Student

**Goal:** Use an expensive, intelligent model to optimize prompts for a cheap, fast model.

| Role | Model | Cost | Strength |
|------|-------|------|----------|
| **Judge** | Gemini 3 Pro | $2/$12 per 1M tokens | Best reasoning, 1501 Elo |
| **Student** | Gemini 2.5 Flash-Lite | $0.10/$0.40 per 1M tokens | Fastest, lowest cost |

**The Economics:** Pay once to optimize $\to$ Save on every inference forever.

---

### The Workflow

```
1. Define task + evaluation criteria
2. Write initial system prompt for Flash-Lite
3. Run Flash-Lite on test cases
4. Gemini 3 Pro analyzes failures
5. Gemini 3 Pro rewrites the prompt
6. Repeat until convergence
```

**Key Insight:** Flash-Lite is 30-120x cheaper than Pro. A 10% quality boost from prompt optimization = massive ROI at scale.

---

### Example Tasks for Optimization

Pick one for today's exercise:

**1. Structured Data Extraction**
> Extract product info (name, price, specs) from e-commerce HTML snippets into JSON. Evaluate on schema compliance + field accuracy.

**2. Code Review Classification**
> Classify code changes as: `bug_fix`, `feature`, `refactor`, `docs`, `test`. Evaluate on F1 score against labeled PR dataset.

**3. Croatian-English Translation**
> Translate technical documentation. Evaluate on BLEU score + terminology consistency (e.g., "funkcija" $\to$ "function" not "feature").

---

<!-- _class: lead -->

# Q&A
### Reference Material: AI Engineer Code Summit 2025 Transcripts
